networks:
  ddos-net:
    driver: bridge

services:
  # Zookeeper (cần thiết cho Kafka)
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.3
    container_name: zookeeper
    networks:
      - ddos-net
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  # Kafka (message broker)
  kafka:
    image: confluentinc/cp-kafka:7.5.3
    container_name: kafka
    networks:
      - ddos-net
    ports:
      - "29092:29092"
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,EXTERNAL://localhost:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CREATE_TOPICS: "ddos_packets_raw:1:1"

  # Spark Master
  spark-master:
    build:
      context: ./docker/spark-run
      dockerfile: Dockerfile
    container_name: spark-master
    user: root
    networks:
      - ddos-net
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark_app:/opt/spark-apps
      - ./spark_app/ml_model:/opt/ml-model 
      - ./data:/opt/spark-data
      - ./spark_output:/opt/spark-output

    environment:
      - SPARK_MODE=master
      - HOME=/tmp
      - HADOOP_USER_NAME=spark
      - USER=spark
      - HADOOP_CONF_DIR=/tmp
      - JAVA_OPTS=-Djava.security.auth.login.config=/dev/null

  # Spark Worker
  spark-worker:
    build:
      context: ./docker/spark-run
      dockerfile: Dockerfile
    container_name: spark-worker
    networks:
      - ddos-net
    depends_on:
      - spark-master
    volumes:
      - ./spark_app:/opt/spark-apps
      - ./spark_app/ml_model:/opt/ml-model 
      - ./data:/opt/spark-data
      - ./spark_output:/opt/spark-output

    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - HOME=/tmp
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no

  kafka-run:
    build:
      context: ./docker/kafka-run
      dockerfile: Dockerfile
    container_name: kafka-run
    networks:
      - ddos-net
    volumes:
      - ./data:/app/data
      - ./producer:/app/producer
      - ./spark_app:/app/spark_app
      - ./kafka_producer:/app/kafka_producer
    depends_on:
      - kafka
      - spark-master
      - spark-worker

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.12.2
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.transport.ssl.enabled=false
    ports:
      - "9200:9200"
    networks:
      - ddos-net
  kibana:
    image: docker.elastic.co/kibana/kibana:8.12.2
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - "5601:5601"
    networks:
      - ddos-net
    depends_on:
      - elasticsearch

  uploader:
    build:
      context: ./docker/uploader
    container_name: uploader
    depends_on:
      - elasticsearch
    networks:
      - ddos-net
    volumes:
      - ./data:/app/data