# ๐ DDoS Detection using Spark MLlib (Random Forest Model)

## ๐ Mแปฅc tiรชu

แปจng dแปฅng phรกt hiแปn cรกc luแปng dแปฏ liแปu DDoS theo thแปi gian thแปฑc (real-time) bแบฑng cรกch sแปญ dแปฅng mรด hรฌnh Random Forest ฤฦฐแปฃc huแบฅn luyแปn trรชn Spark MLlib. Dแปฏ liแปu ฤแบงu vรo ฤแบฟn tแปซ Kafka vร ฤแบงu ra lร nhรฃn phรขn loแบกi: `Normal` hoแบทc `DDoS`.

---

## ๐งฐ Yรชu cแบงu hแป thแปng

* Apache Spark 3.x (hแป trแปฃ Structured Streaming)
* Kafka topic chแปฉa dแปฏ liแปu real-time (vรญ dแปฅ: `ddos_packets_raw`)
* Mรด hรฌnh huแบฅn luyแปn sแบตn (`rf_binary_model`)
* File ฤแบทc trฦฐng yรชu cแบงu (`expected_features.txt`)
* Docker Compose (nแบฟu chแบกy theo dแบกng cแปฅm Spark + Kafka)

---

## ๐ Cแบฅu trรบc thฦฐ mแปฅc

```
/opt/
โโโ spark-apps/
โ   โโโ predict_rf_streaming.py        # ๐ฎ Script dแปฑ ฤoรกn real-time
โโโ ml-model/
โ   โโโ rf_binary_model/               # ๐ฒ Mรด hรฌnh Random Forest ฤรฃ huแบฅn luyแปn
โ   โโโ expected_features.txt          # ๐ Danh sรกch cรกc cแปt ฤแบทc trฦฐng
โโโ spark-data/                        # (Tรนy chแปn) dแปฏ liแปu CSV huแบฅn luyแปn ban ฤแบงu
```

---

## ๐ Cรกch huแบฅn luyแปn mรด hรฌnh (1 lแบงn duy nhแบฅt)

> Nแบฟu bแบกn chฦฐa cรณ mรด hรฌnh, hรฃy chแบกy script sau ฤแป train:

```bash
docker exec -it spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/train_rf_model.py
```

Sau khi chแบกy xong, thฦฐ mแปฅc `/opt/ml-model/rf_binary_model` sแบฝ chแปฉa pipeline ฤรฃ huแบฅn luyแปn. File `/opt/ml-model/expected_features.txt` cลฉng ฤฦฐแปฃc tแบกo kรจm.

---

## ๐ Cรกch chแบกy dแปฑ ฤoรกn real-time

### 1. Kafka phแบฃi gแปญi dแปฏ liแปu lรชn topic (vรญ dแปฅ `ddos_packets_raw`), mแปi bแบฃn ghi lร 1 JSON object vแปi cรกc ฤแบทc trฦฐng ฤแปnh lฦฐแปฃng (numeric features).

Vรญ dแปฅ mแปt bแบฃn ghi:

```json
{
  "Unnamed_0": 1,
  "Source_IP": "192.168.1.1",
  "Destination_IP": "10.0.0.5",
  "Timestamp": "2025-07-10T15:00:00Z",
  "SimillarHTTP": 0,
  "Inbound": 1,
  "Flow_Duration": 12000,
  "Total_Fwd_Packets": 10,
  "Total_Backward_Packets": 5
  // ... cรกc ฤแบทc trฦฐng khรกc
}
```

> โ๏ธ Bแบกn cแบงn xแปญ lรฝ ฤแบงu vรo ฤแป loแบกi bแป cรกc cแปt khรดng nแบฑm trong danh sรกch `expected_features.txt`, chแบณng hแบกn nhฦฐ: `Unnamed_0`, `Source_IP`, `Destination_IP`, `Timestamp`, `SimillarHTTP`, `Inbound`...

---

## ๐ง Lรm sแบกch dแปฏ liแปu ฤแบงu vรo

Trฦฐแปc khi ฤฦฐa vรo mรด hรฌnh, cแบงn ฤแบฃm bแบฃo dแปฏ liแปu:

* Lรm sแบกch tรชn trฦฐแปng dแปฏ liแปu
* Chแป bao gแปm cรกc cแปt trong `expected_features.txt`
* Khรดng chแปฉa giรก trแป `null`, `NaN`, `inf`, `-inf`
* Tแบฅt cแบฃ giรก trแป lร kiแปu sแป (`float` hoแบทc `double`)

Vรญ dแปฅ ฤoแบกn code lรm sแบกch:

```python
from pyspark.sql.functions import col, when

# โ๏ธ Lรm sแบกch tรชn cแปt
df = df.toDF(*[c.strip() for c in df.columns])
for old_name in df.columns:
    new_name = old_name.replace(" ", "_").replace(".", "_")
    if old_name != new_name:
        df = df.withColumnRenamed(old_name, new_name)

# Loแบกi bแป cรกc cแปt khรดng nแบฑm trong expected_features.txt
df = df.select(*expected_features)

# Thay thแบฟ Inf / -Inf bแบฑng null
for c in df.columns:
    df = df.withColumn(c, when(col(c).isin(float("inf"), float("-inf")), None).otherwise(col(c)))

# Loแบกi bแป dรฒng null
df = df.dropna()
```

---

## ๐งช Viแบฟt script chแบกy mรด hรฌnh real-time (`predict_rf_streaming.py`)

Bแบกn cรณ thแป viแบฟt script dแปฑ ฤoรกn theo thแปi gian thแปฑc nhฦฐ sau:

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, col, when
from pyspark.sql.types import StructType, DoubleType
from pyspark.ml import PipelineModel

# Tแบกo Spark session vแปi Structured Streaming
spark = SparkSession.builder \
    .appName("Real-time DDoS Prediction") \
    .getOrCreate()
spark.sparkContext.setLogLevel("WARN")

# ฤแปc danh sรกch cแปt tแปซ file expected_features.txt
with open("/opt/ml-model/expected_features.txt") as f:
    feature_cols = [line.strip() for line in f if line.strip()]

# Tแบกo schema cho JSON ฤแบงu vรo
schema = StructType()
for col_name in feature_cols:
    schema = schema.add(col_name, DoubleType())

# ฤแปc luแปng tแปซ Kafka
raw_df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9092") \
    .option("subscribe", "ddos_packets_raw") \
    .load()

# Parse JSON vร chแปn cรกc cแปt ฤรบng thแปฉ tแปฑ
parsed_df = raw_df.selectExpr("CAST(value AS STRING) as json") \
    .select(from_json(col("json"), schema).alias("data")) \
    .select("data.*")

# Lรm sแบกch dแปฏ liแปu (nแบฟu cแบงn)
for c in feature_cols:
    parsed_df = parsed_df.withColumn(c, when(col(c).isin(float("inf"), float("-inf")), None).otherwise(col(c)))
parsed_df = parsed_df.dropna()

# Tแบฃi mรด hรฌnh ฤรฃ huแบฅn luyแปn
model = PipelineModel.load("/opt/ml-model/rf_binary_model")

# Dแปฑ ฤoรกn
predictions = model.transform(parsed_df)

# Chuyแปn kแบฟt quแบฃ ra nhรฃn (0.0 โ Normal, 1.0 โ DDoS)
result = predictions.withColumn("Label", 
            when(col("prediction") == 1.0, "DDoS").otherwise("Normal")).select("Label")

# Ghi ra console
query = result.writeStream \
    .outputMode("append") \
    .format("console") \
    .option("truncate", False) \
    .start()

query.awaitTermination()
```

---

## ๐ Chแบกy script trong container

```bash
docker exec -it spark-master spark-submit \
  --master spark://spark-master:7077 \
  /opt/spark-apps/predict_rf_streaming.py
```

---

## ๐ฅ ฤแบงu ra

Dแปฑ ฤoรกn xuแบฅt hiแปn trong console dฦฐแปi dแบกng:

```
+----------+
| Label    |
+----------+
| DDoS     |
| Normal   |
+----------+
```

Bแบกn cรณ thแป tรนy chแปn:

* Ghi kแบฟt quแบฃ ra file CSV
* Gแปญi tiแบฟp ra Kafka topic khรกc (vรญ dแปฅ `ddos_predictions`)
* Hiแปn thแป trรชn dashboard (Prometheus, Grafana, v.v.)

---

## ๐ Gแปฃi รฝ mแป rแปng

* Tรญch hแปฃp vแปi hแป thแปng cแบฃnh bรกo (email, Telegram)
* Tแปฑ ฤแปng lฦฐu cรกc Flow bแป nghi lร DDoS ฤแป huแบฅn luyแปn lแบกi mรด hรฌnh
* Phรขn loแบกi nhiแปu loแบกi tแบฅn cรดng (DoS, Scan, BruteForce, ...)

---

## ๐ Liรชn hแป

Nแบฟu cรณ vแบฅn ฤแป khi chแบกy, hรฃy kiแปm tra:

* Mรด hรฌnh ฤรฃ ฤฦฐแปฃc lฦฐu ฤรบng vแป trรญ `/opt/ml-model/rf_binary_model`
* File `expected_features.txt` ฤรบng thแปฉ tแปฑ vร ฤแปง cแปt
* Kafka ฤang ฤแบฉy dแปฏ liแปu dแบกng JSON ฤรบng schema

> Chรบc bแบกn phรกt hiแปn DDoS thรnh cรดng vแปi Spark! ๐
