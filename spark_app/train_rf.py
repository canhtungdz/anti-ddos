from pyspark.sql import SparkSession
from pyspark.sql.functions import col, when, trim, upper
from pyspark.ml.feature import StringIndexer, VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml import Pipeline
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import os

#  T·∫°o Spark session
spark = SparkSession.builder \
    .appName("Train Binary Random Forest for DDoS") \
    .getOrCreate()
spark.sparkContext.setLogLevel("WARN")

#  ƒê·ªçc t·∫•t c·∫£ file .csv
df = spark.read.csv("/opt/spark-data/*.csv", header=True, inferSchema=True)

#  L√†m s·∫°ch t√™n c·ªôt
df = df.toDF(*[c.strip() for c in df.columns])
for old_name in df.columns:
    new_name = old_name.replace(" ", "_").replace(".", "_")
    if old_name != new_name:
        df = df.withColumnRenamed(old_name, new_name)

#  Xo√° c·ªôt kh√¥ng c·∫ßn thi·∫øt
cols_to_drop = ['Unnamed:_0', 'Flow_ID', 'Source_IP', 'Destination_IP', 'Timestamp', 'SimillarHTTP', 'Inbound']
df = df.drop(*[col_name for col_name in cols_to_drop if col_name in df.columns])

#  L√†m s·∫°ch nh√£n (Label)
df = df.withColumn("Label_cleaned", upper(trim(col("Label"))))

#  Chuy·ªÉn nh√£n sang binary: BENIGN ‚Üí 0.0, c√≤n l·∫°i ‚Üí 1.0
df = df.withColumn("binary_label", when(col("Label_cleaned") == "BENIGN", 0.0).otherwise(1.0))

#  Thay th·∫ø Inf v√† NaN
for c in df.columns:
    if c not in ["binary_label", "Label", "Label_cleaned"]:
        df = df.withColumn(c, when(col(c).isin(float("inf"), float("-inf")), None).otherwise(col(c)))

df = df.dropna()

#  Ki·ªÉm tra r·ªóng
if df.count() == 0:
    raise ValueError(" D·ªØ li·ªáu r·ªóng sau khi l√†m s·∫°ch!")

#  Th·ªëng k√™ ph√¢n ph·ªëi nh√£n
print(" Ph√¢n ph·ªëi nh√£n sau x·ª≠ l√Ω:")
df.groupBy("binary_label").count().orderBy("binary_label").show()

#  Vector h√≥a ƒë·∫∑c tr∆∞ng
feature_cols = [c for c in df.columns if c not in ["Label", "Label_cleaned", "binary_label"]]
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")

# üå≤ Random Forest ph√¢n lo·∫°i nh·ªã ph√¢n
rf = RandomForestClassifier(
    labelCol="binary_label",
    featuresCol="features",
    numTrees=100,
    maxDepth=6,
    impurity="gini",
    featureSubsetStrategy="sqrt"
)

#  Pipeline
pipeline = Pipeline(stages=[assembler, rf])

#  Chia train/test
train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)

#  Hu·∫•n luy·ªán
print(" ƒêang hu·∫•n luy·ªán m√¥ h√¨nh Random Forest c√≥ c√¢n b·∫±ng nh√£n...")
rf_model = pipeline.fit(train_data)

#  L∆∞u m√¥ h√¨nh
model_path = "/opt/ml-model/rf_binary_model"
rf_model.write().overwrite().save(model_path)
print(f" M√¥ h√¨nh ƒë√£ l∆∞u t·∫°i: {model_path}")

#  Ghi danh s√°ch ƒë·∫∑c tr∆∞ng ra file
features_txt_path = "/opt/ml-model/expected_features.txt"
os.makedirs("/opt/ml-model", exist_ok=True)
with open(features_txt_path, "w") as f:
    for col_name in feature_cols:
        f.write(col_name + "\n")
print(f" ƒê√£ l∆∞u danh s√°ch ƒë·∫∑c tr∆∞ng v√†o: {features_txt_path}")

#  D·ª± ƒëo√°n
predictions = rf_model.transform(test_data)

#  Ma tr·∫≠n nh·∫ßm l·∫´n
print("\n Ma tr·∫≠n nh·∫ßm l·∫´n:")
predictions.groupBy("binary_label", "prediction").count().orderBy("binary_label", "prediction").show()

#  ƒê√°nh gi√°
evaluator = MulticlassClassificationEvaluator(labelCol="binary_label", predictionCol="prediction")
accuracy = evaluator.setMetricName("accuracy").evaluate(predictions)
precision = evaluator.setMetricName("weightedPrecision").evaluate(predictions)
recall = evaluator.setMetricName("weightedRecall").evaluate(predictions)
f1 = evaluator.setMetricName("f1").evaluate(predictions)

#  In k·∫øt qu·∫£
print("\n K·∫æT QU·∫¢ ƒê√ÅNH GI√Å M√î H√åNH:")
print(f" Accuracy        : {accuracy * 100:.2f}%")
print(f" Precision       : {precision * 100:.2f}%")
print(f" Recall          : {recall * 100:.2f}%")
print(f" F1 Score        : {f1 * 100:.2f}%")
